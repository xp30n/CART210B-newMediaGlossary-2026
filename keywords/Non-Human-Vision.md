## Non-Human Vision

Joanna Zylinska explains that “What is meant by nonhuman photography here is not just photos taken by agents that are not human, such as CCTV cameras, body scanners, space satellites or Google Street View" [^1]. "Non-human vision" refers to a method of seeing that is not centered or limited to human perception. 

In the traditional sense, "vision" is what we see through our eyes and what is interpreted by our brains. Images contained materials that were "tools used to paint, create a photograph or print pictures." [^2] From this perspective, vision is objective, and very much human.

But the idea of a "non-human vision" challenges that. It's a process of visualizing things outside of the human senses. This includes:

- Machine Vision (Like face ID, surveillance systems)
- Radars (Infrared, thermal)
- Computational Systems 

The main idea is that non-human vision doesn't see things the way that humans do. 

What makes it significant in new media is the fact that we are reliant on forms of perception outside of our own vision. Before, images, moving or not, were as they are. You take a photo or watch a film and that's it. But now, images are heavily processed by machines like our phones and our computers before we edit them or before they're seen by other people. This makes perception no longer human, but computational. This changes the significance of images. While they are things that we look at and enjoy, they have also become tools for systems and algorithms.

This relates to current new media technologies because most digital systems see things before we do. When you take a photo or video, your phone, computer or camera scans it, detects the things within the picture and categorizes it into data. The machine is processing the image before we do. This is used in many places. Facial recognition systems like Face ID scan your face, tag key points of your features, inputs them into a database and makse a decision based on that interpretation. The machine performs the recognition, showing us a non-human vision in action. AI is also heavily prevalent in this space as well. There's AI image search, reverse search. Google photos uses AI to categorize images into groups. (I use google photos a lot so this is more of a personal observation). But there's a collection within google photos that p[laces your images into groups of people or pets, photos taken in certain locations, whether they're screenshots or documents. These are just some of the ways we see non-human visions come to life in every day practices. 

[^1]: Zylinska, Joanna. Nonhuman Photography. Cambridge, MA: MIT Press, 2017.
[^2]: Paglen, Trevor. “Invisible Images (Your Pictures Are Looking at You).” The New Inquiry, December 8, 2016.
